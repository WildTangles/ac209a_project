{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from shapely.prepared import prep\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful arrays to translate between naming conventions\n",
    "\n",
    "election_year_list = np.array([1992, 1994, 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, \n",
    "                                   2014, 2016, 2018])\n",
    "congress_ID_list = np.array([103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116])\n",
    "\n",
    "state_names = np.array(['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', \n",
    "               'COLORADO', 'CONNECTICUT', 'DELAWARE', 'FLORIDA', 'GEORGIA', \n",
    "               'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', \n",
    "               'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', \n",
    "               'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', \n",
    "               'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', \n",
    "               'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', \n",
    "               'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', \n",
    "               'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', \n",
    "               'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'])\n",
    "\n",
    "state_abbrs = np.array(['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL',\n",
    "              'IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT',\n",
    "              'NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI',\n",
    "              'SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY'])\n",
    "\n",
    "state_fips = np.array([1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, \n",
    "                       24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
    "                       41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proj.4 string:\n",
    "# +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "congress_ID = '114'\n",
    "shpfilename = 'districtShapes-{0}/districts{0}.shp'.format(congress_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AK_01_2016 was read in.\n",
      "DE_01_2016 was read in.\n",
      "MT_01_2016 was read in.\n",
      "ND_01_2016 was read in.\n",
      "SD_01_2016 was read in.\n",
      "VT_01_2016 was read in.\n",
      "WY_01_2016 was read in.\n",
      "AL_01_2016 was read in.\n",
      "AZ_01_2016 was read in.\n",
      "AR_01_2016 was read in.\n",
      "CA_01_2016 was read in.\n",
      "CO_01_2016 was read in.\n",
      "CT_01_2016 was read in.\n",
      "FL_01_2016 was read in.\n",
      "GA_01_2016 was read in.\n",
      "HI_01_2016 was read in.\n",
      "ID_01_2016 was read in.\n",
      "IL_01_2016 was read in.\n",
      "IN_01_2016 was read in.\n",
      "IA_01_2016 was read in.\n",
      "KS_01_2016 was read in.\n",
      "KY_01_2016 was read in.\n",
      "LA_01_2016 was read in.\n",
      "ME_01_2016 was read in.\n",
      "MD_01_2016 was read in.\n",
      "MA_01_2016 was read in.\n",
      "MI_01_2016 was read in.\n",
      "MN_01_2016 was read in.\n",
      "MS_01_2016 was read in.\n",
      "MO_01_2016 was read in.\n",
      "NE_01_2016 was read in.\n",
      "NV_01_2016 was read in.\n",
      "NH_01_2016 was read in.\n",
      "NJ_01_2016 was read in.\n",
      "NM_01_2016 was read in.\n",
      "NY_01_2016 was read in.\n",
      "NC_01_2016 was read in.\n",
      "OH_01_2016 was read in.\n",
      "OK_01_2016 was read in.\n",
      "OR_01_2016 was read in.\n",
      "PA_01_2016 was read in.\n",
      "RI_01_2016 was read in.\n",
      "SC_01_2016 was read in.\n",
      "TN_01_2016 was read in.\n",
      "TX_01_2016 was read in.\n",
      "UT_01_2016 was read in.\n",
      "VA_01_2016 was read in.\n",
      "WA_01_2016 was read in.\n",
      "WV_01_2016 was read in.\n",
      "WI_01_2016 was read in.\n",
      "AL_02_2016 was read in.\n",
      "AZ_02_2016 was read in.\n",
      "AR_02_2016 was read in.\n",
      "CA_02_2016 was read in.\n",
      "CO_02_2016 was read in.\n",
      "CT_02_2016 was read in.\n",
      "FL_02_2016 was read in.\n",
      "GA_02_2016 was read in.\n",
      "HI_02_2016 was read in.\n",
      "ID_02_2016 was read in.\n",
      "IL_02_2016 was read in.\n",
      "IN_02_2016 was read in.\n",
      "IA_02_2016 was read in.\n",
      "KS_02_2016 was read in.\n",
      "KY_02_2016 was read in.\n",
      "LA_02_2016 was read in.\n",
      "ME_02_2016 was read in.\n",
      "MD_02_2016 was read in.\n",
      "MA_02_2016 was read in.\n",
      "MI_02_2016 was read in.\n",
      "MN_02_2016 was read in.\n",
      "MS_02_2016 was read in.\n",
      "MO_02_2016 was read in.\n",
      "NE_02_2016 was read in.\n",
      "NV_02_2016 was read in.\n",
      "NH_02_2016 was read in.\n",
      "NJ_02_2016 was read in.\n",
      "NM_02_2016 was read in.\n",
      "NY_02_2016 was read in.\n",
      "NC_02_2016 was read in.\n",
      "OH_02_2016 was read in.\n",
      "OK_02_2016 was read in.\n",
      "OR_02_2016 was read in.\n",
      "PA_02_2016 was read in.\n",
      "RI_02_2016 was read in.\n",
      "SC_02_2016 was read in.\n",
      "TN_02_2016 was read in.\n",
      "TX_02_2016 was read in.\n",
      "UT_02_2016 was read in.\n",
      "VA_02_2016 was read in.\n",
      "WA_02_2016 was read in.\n",
      "WV_02_2016 was read in.\n",
      "WI_02_2016 was read in.\n",
      "AL_03_2016 was read in.\n",
      "AZ_03_2016 was read in.\n",
      "AR_03_2016 was read in.\n",
      "CA_03_2016 was read in.\n",
      "CO_03_2016 was read in.\n",
      "CT_03_2016 was read in.\n",
      "FL_03_2016 was read in.\n",
      "GA_03_2016 was read in.\n",
      "IL_03_2016 was read in.\n",
      "IN_03_2016 was read in.\n",
      "IA_03_2016 was read in.\n",
      "KS_03_2016 was read in.\n",
      "KY_03_2016 was read in.\n",
      "LA_03_2016 was read in.\n",
      "MD_03_2016 was read in.\n",
      "MA_03_2016 was read in.\n",
      "MI_03_2016 was read in.\n",
      "MN_03_2016 was read in.\n",
      "MS_03_2016 was read in.\n",
      "MO_03_2016 was read in.\n",
      "NE_03_2016 was read in.\n",
      "NV_03_2016 was read in.\n",
      "NJ_03_2016 was read in.\n",
      "NM_03_2016 was read in.\n",
      "NY_03_2016 was read in.\n",
      "NC_03_2016 was read in.\n",
      "OH_03_2016 was read in.\n",
      "OK_03_2016 was read in.\n",
      "OR_03_2016 was read in.\n",
      "PA_03_2016 was read in.\n",
      "SC_03_2016 was read in.\n",
      "TN_03_2016 was read in.\n",
      "TX_03_2016 was read in.\n",
      "UT_03_2016 was read in.\n",
      "VA_03_2016 was read in.\n",
      "WA_03_2016 was read in.\n",
      "WV_03_2016 was read in.\n",
      "WI_03_2016 was read in.\n",
      "AL_04_2016 was read in.\n",
      "AZ_04_2016 was read in.\n",
      "AR_04_2016 was read in.\n",
      "CA_04_2016 was read in.\n",
      "CO_04_2016 was read in.\n",
      "CT_04_2016 was read in.\n",
      "FL_04_2016 was read in.\n",
      "GA_04_2016 was read in.\n",
      "IL_04_2016 was read in.\n",
      "IN_04_2016 was read in.\n",
      "IA_04_2016 was read in.\n",
      "KS_04_2016 was read in.\n",
      "KY_04_2016 was read in.\n",
      "LA_04_2016 was read in.\n",
      "MD_04_2016 was read in.\n",
      "MA_04_2016 was read in.\n",
      "MI_04_2016 was read in.\n",
      "MN_04_2016 was read in.\n",
      "MS_04_2016 was read in.\n",
      "MO_04_2016 was read in.\n",
      "NV_04_2016 was read in.\n",
      "NJ_04_2016 was read in.\n",
      "NY_04_2016 was read in.\n",
      "NC_04_2016 was read in.\n",
      "OH_04_2016 was read in.\n",
      "OK_04_2016 was read in.\n",
      "OR_04_2016 was read in.\n",
      "PA_04_2016 was read in.\n",
      "SC_04_2016 was read in.\n",
      "TN_04_2016 was read in.\n",
      "TX_04_2016 was read in.\n",
      "UT_04_2016 was read in.\n",
      "VA_04_2016 was read in.\n",
      "WA_04_2016 was read in.\n",
      "WI_04_2016 was read in.\n",
      "AL_05_2016 was read in.\n",
      "AZ_05_2016 was read in.\n",
      "CA_05_2016 was read in.\n",
      "CO_05_2016 was read in.\n",
      "CT_05_2016 was read in.\n",
      "FL_05_2016 was read in.\n",
      "GA_05_2016 was read in.\n",
      "IL_05_2016 was read in.\n",
      "IN_05_2016 was read in.\n",
      "KY_05_2016 was read in.\n",
      "LA_05_2016 was read in.\n",
      "MD_05_2016 was read in.\n",
      "MA_05_2016 was read in.\n",
      "MI_05_2016 was read in.\n",
      "MN_05_2016 was read in.\n",
      "MO_05_2016 was read in.\n",
      "NJ_05_2016 was read in.\n",
      "NY_05_2016 was read in.\n",
      "NC_05_2016 was read in.\n",
      "OH_05_2016 was read in.\n",
      "OK_05_2016 was read in.\n",
      "OR_05_2016 was read in.\n",
      "PA_05_2016 was read in.\n",
      "SC_05_2016 was read in.\n",
      "TN_05_2016 was read in.\n",
      "TX_05_2016 was read in.\n",
      "VA_05_2016 was read in.\n",
      "WA_05_2016 was read in.\n",
      "WI_05_2016 was read in.\n",
      "AL_06_2016 was read in.\n",
      "AZ_06_2016 was read in.\n",
      "CA_06_2016 was read in.\n",
      "CO_06_2016 was read in.\n",
      "FL_06_2016 was read in.\n",
      "GA_06_2016 was read in.\n",
      "IL_06_2016 was read in.\n",
      "IN_06_2016 was read in.\n",
      "KY_06_2016 was read in.\n",
      "LA_06_2016 was read in.\n",
      "MD_06_2016 was read in.\n",
      "MA_06_2016 was read in.\n",
      "MI_06_2016 was read in.\n",
      "MN_06_2016 was read in.\n",
      "MO_06_2016 was read in.\n",
      "NJ_06_2016 was read in.\n",
      "NY_06_2016 was read in.\n",
      "NC_06_2016 was read in.\n",
      "OH_06_2016 was read in.\n",
      "PA_06_2016 was read in.\n",
      "SC_06_2016 was read in.\n",
      "TN_06_2016 was read in.\n",
      "TX_06_2016 was read in.\n",
      "VA_06_2016 was read in.\n",
      "WA_06_2016 was read in.\n",
      "WI_06_2016 was read in.\n",
      "AL_07_2016 was read in.\n",
      "AZ_07_2016 was read in.\n",
      "CA_07_2016 was read in.\n",
      "CO_07_2016 was read in.\n",
      "FL_07_2016 was read in.\n",
      "GA_07_2016 was read in.\n",
      "IL_07_2016 was read in.\n",
      "IN_07_2016 was read in.\n",
      "MD_07_2016 was read in.\n",
      "MA_07_2016 was read in.\n",
      "MI_07_2016 was read in.\n",
      "MN_07_2016 was read in.\n",
      "MO_07_2016 was read in.\n",
      "NJ_07_2016 was read in.\n",
      "NY_07_2016 was read in.\n",
      "NC_07_2016 was read in.\n",
      "OH_07_2016 was read in.\n",
      "PA_07_2016 was read in.\n",
      "SC_07_2016 was read in.\n",
      "TN_07_2016 was read in.\n",
      "TX_07_2016 was read in.\n",
      "VA_07_2016 was read in.\n",
      "WA_07_2016 was read in.\n",
      "WI_07_2016 was read in.\n",
      "AZ_08_2016 was read in.\n",
      "CA_08_2016 was read in.\n",
      "FL_08_2016 was read in.\n",
      "GA_08_2016 was read in.\n",
      "IL_08_2016 was read in.\n",
      "IN_08_2016 was read in.\n",
      "MD_08_2016 was read in.\n",
      "MA_08_2016 was read in.\n",
      "MI_08_2016 was read in.\n",
      "MN_08_2016 was read in.\n",
      "MO_08_2016 was read in.\n",
      "NJ_08_2016 was read in.\n",
      "NY_08_2016 was read in.\n",
      "NC_08_2016 was read in.\n",
      "OH_08_2016 was read in.\n",
      "PA_08_2016 was read in.\n",
      "TN_08_2016 was read in.\n",
      "TX_08_2016 was read in.\n",
      "VA_08_2016 was read in.\n",
      "WA_08_2016 was read in.\n",
      "WI_08_2016 was read in.\n",
      "AZ_09_2016 was read in.\n",
      "CA_09_2016 was read in.\n",
      "FL_09_2016 was read in.\n",
      "GA_09_2016 was read in.\n",
      "IL_09_2016 was read in.\n",
      "IN_09_2016 was read in.\n",
      "MA_09_2016 was read in.\n",
      "MI_09_2016 was read in.\n",
      "NJ_09_2016 was read in.\n",
      "NY_09_2016 was read in.\n",
      "NC_09_2016 was read in.\n",
      "OH_09_2016 was read in.\n",
      "PA_09_2016 was read in.\n",
      "TN_09_2016 was read in.\n",
      "TX_09_2016 was read in.\n",
      "VA_09_2016 was read in.\n",
      "WA_09_2016 was read in.\n",
      "CA_10_2016 was read in.\n",
      "FL_10_2016 was read in.\n",
      "GA_10_2016 was read in.\n",
      "IL_10_2016 was read in.\n",
      "MI_10_2016 was read in.\n",
      "NJ_10_2016 was read in.\n",
      "NY_10_2016 was read in.\n",
      "NC_10_2016 was read in.\n",
      "OH_10_2016 was read in.\n",
      "PA_10_2016 was read in.\n",
      "TX_10_2016 was read in.\n",
      "VA_10_2016 was read in.\n",
      "WA_10_2016 was read in.\n",
      "CA_11_2016 was read in.\n",
      "FL_11_2016 was read in.\n",
      "GA_11_2016 was read in.\n",
      "IL_11_2016 was read in.\n",
      "MI_11_2016 was read in.\n",
      "NJ_11_2016 was read in.\n",
      "NY_11_2016 was read in.\n",
      "NC_11_2016 was read in.\n",
      "OH_11_2016 was read in.\n",
      "PA_11_2016 was read in.\n",
      "TX_11_2016 was read in.\n",
      "VA_11_2016 was read in.\n",
      "CA_12_2016 was read in.\n",
      "FL_12_2016 was read in.\n",
      "GA_12_2016 was read in.\n",
      "IL_12_2016 was read in.\n",
      "MI_12_2016 was read in.\n",
      "NJ_12_2016 was read in.\n",
      "NY_12_2016 was read in.\n",
      "NC_12_2016 was read in.\n",
      "OH_12_2016 was read in.\n",
      "PA_12_2016 was read in.\n",
      "TX_12_2016 was read in.\n",
      "CA_13_2016 was read in.\n",
      "FL_13_2016 was read in.\n",
      "GA_13_2016 was read in.\n",
      "IL_13_2016 was read in.\n",
      "MI_13_2016 was read in.\n",
      "NY_13_2016 was read in.\n",
      "NC_13_2016 was read in.\n",
      "OH_13_2016 was read in.\n",
      "PA_13_2016 was read in.\n",
      "TX_13_2016 was read in.\n",
      "CA_14_2016 was read in.\n",
      "FL_14_2016 was read in.\n",
      "GA_14_2016 was read in.\n",
      "IL_14_2016 was read in.\n",
      "MI_14_2016 was read in.\n",
      "NY_14_2016 was read in.\n",
      "OH_14_2016 was read in.\n",
      "PA_14_2016 was read in.\n",
      "TX_14_2016 was read in.\n",
      "CA_15_2016 was read in.\n",
      "FL_15_2016 was read in.\n",
      "IL_15_2016 was read in.\n",
      "NY_15_2016 was read in.\n",
      "OH_15_2016 was read in.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PA_15_2016 was read in.\n",
      "TX_15_2016 was read in.\n",
      "CA_16_2016 was read in.\n",
      "FL_16_2016 was read in.\n",
      "IL_16_2016 was read in.\n",
      "NY_16_2016 was read in.\n",
      "OH_16_2016 was read in.\n",
      "PA_16_2016 was read in.\n",
      "TX_16_2016 was read in.\n",
      "CA_17_2016 was read in.\n",
      "FL_17_2016 was read in.\n",
      "IL_17_2016 was read in.\n",
      "NY_17_2016 was read in.\n",
      "PA_17_2016 was read in.\n",
      "TX_17_2016 was read in.\n",
      "CA_18_2016 was read in.\n",
      "FL_18_2016 was read in.\n",
      "IL_18_2016 was read in.\n",
      "NY_18_2016 was read in.\n",
      "PA_18_2016 was read in.\n",
      "TX_18_2016 was read in.\n",
      "CA_19_2016 was read in.\n",
      "FL_19_2016 was read in.\n",
      "NY_19_2016 was read in.\n",
      "TX_19_2016 was read in.\n",
      "CA_20_2016 was read in.\n",
      "FL_20_2016 was read in.\n",
      "NY_20_2016 was read in.\n",
      "TX_20_2016 was read in.\n",
      "CA_21_2016 was read in.\n",
      "FL_21_2016 was read in.\n",
      "NY_21_2016 was read in.\n",
      "TX_21_2016 was read in.\n",
      "CA_22_2016 was read in.\n",
      "FL_22_2016 was read in.\n",
      "NY_22_2016 was read in.\n",
      "TX_22_2016 was read in.\n",
      "CA_23_2016 was read in.\n",
      "FL_23_2016 was read in.\n",
      "NY_23_2016 was read in.\n",
      "TX_23_2016 was read in.\n",
      "CA_24_2016 was read in.\n",
      "FL_24_2016 was read in.\n",
      "NY_24_2016 was read in.\n",
      "TX_24_2016 was read in.\n",
      "CA_25_2016 was read in.\n",
      "FL_25_2016 was read in.\n",
      "NY_25_2016 was read in.\n",
      "TX_25_2016 was read in.\n",
      "CA_26_2016 was read in.\n",
      "FL_26_2016 was read in.\n",
      "NY_26_2016 was read in.\n",
      "TX_26_2016 was read in.\n",
      "CA_27_2016 was read in.\n",
      "FL_27_2016 was read in.\n",
      "NY_27_2016 was read in.\n",
      "TX_27_2016 was read in.\n",
      "CA_28_2016 was read in.\n",
      "TX_28_2016 was read in.\n",
      "CA_29_2016 was read in.\n",
      "TX_29_2016 was read in.\n",
      "CA_30_2016 was read in.\n",
      "TX_30_2016 was read in.\n",
      "CA_31_2016 was read in.\n",
      "TX_31_2016 was read in.\n",
      "CA_32_2016 was read in.\n",
      "TX_32_2016 was read in.\n",
      "CA_33_2016 was read in.\n",
      "TX_33_2016 was read in.\n",
      "CA_34_2016 was read in.\n",
      "TX_34_2016 was read in.\n",
      "CA_35_2016 was read in.\n",
      "TX_35_2016 was read in.\n",
      "CA_36_2016 was read in.\n",
      "TX_36_2016 was read in.\n",
      "CA_37_2016 was read in.\n",
      "CA_38_2016 was read in.\n",
      "CA_39_2016 was read in.\n",
      "CA_40_2016 was read in.\n",
      "CA_41_2016 was read in.\n",
      "CA_42_2016 was read in.\n",
      "CA_43_2016 was read in.\n",
      "CA_44_2016 was read in.\n",
      "CA_45_2016 was read in.\n",
      "CA_46_2016 was read in.\n",
      "CA_47_2016 was read in.\n",
      "CA_48_2016 was read in.\n",
      "CA_49_2016 was read in.\n",
      "CA_50_2016 was read in.\n",
      "CA_51_2016 was read in.\n",
      "CA_52_2016 was read in.\n",
      "CA_53_2016 was read in.\n",
      "11 is not a state.\n",
      "60 is not a state.\n",
      "66 is not a state.\n",
      "69 is not a state.\n",
      "72 is not a state.\n",
      "78 is not a state.\n",
      "District ID is ZZ, which indicates this is not a congressional district.\n",
      "District ID is ZZ, which indicates this is not a congressional district.\n",
      "District ID is ZZ, which indicates this is not a congressional district.\n"
     ]
    }
   ],
   "source": [
    "election_year=2016\n",
    "verbose = True\n",
    "# convert election year to \"Nth Congress\" \n",
    "congress_ID = congress_ID_list[election_year_list==election_year][0]\n",
    "district_df = pickle.load(open('../Datasets/master_index.p','rb'))\n",
    "district_df['shape'] = [np.nan]*district_df.shape[0] # make a blank column\n",
    "district_df['shape'] = district_df['shape'].astype(object) # reassign to object so it can hold shapely stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= next(districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Record: <shapely.geometry.multipolygon.MultiPolygon object at 0x11a7bfb00>, {'STATEFP': '02', 'CD115FP': '00', 'GEOID': '0200', 'NAMELSAD': 'Congressional District (at Large)', 'LSAD': 'C1', 'CDSESSN': '115', 'MTFCC': 'G5200', 'FUNCSTAT': 'N', 'ALAND': 1477946266785, 'AWATER': 245390495931, 'INTPTLAT': '+63.3461909', 'INTPTLON': '-152.8370690'}, <fields>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shapefiles(election_years,verbose=True):\n",
    "    # read in the standard dictionary \n",
    "    district_df = pickle.load(open('../Datasets/master_index.p','rb'))\n",
    "    district_df['shape'] = [np.nan]*district_df.shape[0] # make a blank column\n",
    "    district_df['shape'] = district_df['shape'].astype(object) # reassign to object so it can hold shapely stuff\n",
    "\n",
    "    for election_year in election_years:\n",
    "        # convert election year to \"Nth Congress\" \n",
    "        congress_ID = congress_ID_list[election_year_list==election_year][0]\n",
    "\n",
    "        # read in the shapefile (must be named 'districtsN.shp' in a folder titled 'districtShapesN')\n",
    "        shpfilename = 'districtShapes-{0}/districts{0}.shp'.format(congress_ID)\n",
    "        reader = shpreader.Reader(shpfilename) \n",
    "        districts = reader.records() # get full records\n",
    "        geometries = reader.geometries() # get just the shape\n",
    "\n",
    "        # pre-2016 files come from http://cdmaps.polisci.ucla.edu/\n",
    "        # they are a bit cleaner\n",
    "        if election_year < 2016:\n",
    "            # put the shapefiles into the standard dictionary\n",
    "            for record in reader.records(): # loop over districts\n",
    "                attr = record.attributes # dictionary of information about the district\n",
    "                poly = record.geometry # coordinates of the district as a shapely polygon\n",
    "\n",
    "                # 1) get the state abbr of the district\n",
    "                if any(state_names==attr['STATENAME'].upper()): # filter out districts that aren't in states\n",
    "                    ST = state_abbrs[state_names==attr['STATENAME'].upper()][0]\n",
    "                else: # pretty much just Washington, DC\n",
    "                    print('{} is not a state.'.format(attr['STATENAME'].upper()))\n",
    "                    continue\n",
    "                # 2) get the id of the district\n",
    "                id_int = int(attr['DISTRICT'])\n",
    "                if id_int == 0: # todo: do we want to change this back? Looks like 0 for at-large districts is the convention. \n",
    "                    id_int = 1\n",
    "                ID = '{0:02d}'.format(id_int)\n",
    "                # 3) put it all together into an index\n",
    "                ind = '{}_{}_{}'.format(ST, ID, election_year)\n",
    "                if verbose:\n",
    "                    print('{} was read in.'.format(ind))\n",
    "                # put the polygon in the dictionary\n",
    "                district_df.at[ind,'shape'] = poly\n",
    "            \n",
    "        # 2016 and later are US Census Bureau Tiger Line Files \n",
    "        # (and they're a bit messier)\n",
    "        if election_year >= 2016:\n",
    "            # read in the shapefile (must be named 'districtsN.shp' in a folder titled 'districtShapesN')\n",
    "            shpfilename = 'tl_2016_us_cd{0}/tl_{1}_us_cd{0}.shp'.format(congress_ID,election_year)\n",
    "            reader = shpreader.Reader(shpfilename) \n",
    "            districts = reader.records() # get full records\n",
    "            geometries = reader.geometries() # get just the shape\n",
    "\n",
    "            # put the shapefiles into the standard dictionary\n",
    "            for record in reader.records(): # loop over districts\n",
    "                attr = record.attributes # dictionary of information about the district\n",
    "                poly = record.geometry # coordinates of the district as a shapely polygon\n",
    "\n",
    "                # 1) get the state abbr of the district\n",
    "                if any(state_fips==int(attr['STATEFP'])): # filter out districts that aren't in states\n",
    "                    ST = state_abbrs[state_fips==int(attr['STATEFP'])][0]\n",
    "                else: # pretty much just Washington, DC\n",
    "                    print('{} is not a state.'.format(int(attr['STATEFP'])))\n",
    "                    continue\n",
    "                # 2) get the id of the district\n",
    "                if (attr['CD{}FP'.format(congress_ID)]=='ZZ'):\n",
    "                    print('District ID is ZZ, which indicates this is not a congressional district.')\n",
    "                    continue\n",
    "                else:\n",
    "                    id_int = int(attr['CD{}FP'.format(congress_ID)])\n",
    "                if id_int == 0: # change at-large district ID from 0 to 1 to play nice with our indexing convention.\n",
    "                    # todo: do we want to change this back? Looks like 0 for at-large districts is the convention. \n",
    "                    id_int = 1\n",
    "                ID = '{0:02d}'.format(id_int)\n",
    "                # 3) put it all together into an index\n",
    "                ind = '{}_{}_{}'.format(ST, ID, election_year)\n",
    "                if verbose:\n",
    "                    print('{} was read in.'.format(ind))\n",
    "                # put the polygon in the dictionary\n",
    "                district_df.at[ind,'shape'] = poly\n",
    "    \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find if a district has changed between last year and this year\n",
    "def check_if_districts_changed(this_year, district_df, threshold_for_change=0.1):\n",
    "    # loop over states so you only have to compare districts in-state\n",
    "    # otherwise, comparing each district to 434 other districts would be super slow\n",
    "    for ST in state_abbrs: \n",
    "        prev_year = this_year-2\n",
    "        # get the relevant districts\n",
    "        districts = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==this_year)]\n",
    "        districts_prev = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==prev_year)]\n",
    "        # loop over districts in your current year\n",
    "        for ind,district in districts.iterrows():\n",
    "            # find previous year's district\n",
    "            district_prev = districts_prev.loc[districts_prev['district']==district['district']]\n",
    "            ind_prev = district_prev.index\n",
    "\n",
    "            # determine whether district is new or borders have changed\n",
    "            if ind_prev.shape[0]==0: # if the district didn't exist last year\n",
    "                # then this district is new this year\n",
    "                district_df.loc['border_change',ind] = 'new'\n",
    "            else: \n",
    "                # check if the borders have changed\n",
    "                shape_prev = district_prev['shape'].values[0]\n",
    "                shape = district['shape']\n",
    "\n",
    "                # check if shapes intersect with themselves\n",
    "                if not (shape.is_valid and shape_prev.is_valid): \n",
    "                    # if they do, use buffer to correct this\n",
    "                    print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                    if not shape.is_valid:\n",
    "                        print(ind)\n",
    "                        shape = shape.buffer(0)\n",
    "                    if not shape_prev.is_valid:\n",
    "                        print(ind_prev)\n",
    "                        shape_prev = shape_prev.buffer(0)\n",
    "\n",
    "                # calculate overlap percent\n",
    "                area = shape.area # area of this district\n",
    "                area_prev = shape_prev.area\n",
    "                overlap_area = shape.intersection(shape_prev).area # area of overlap between shape and shape_prev\n",
    "                frac_overlap = overlap_area/np.max([area,area_prev]) # fractional overlap between new and old district\n",
    "                # divide by the larger of the old or new district\n",
    "                \n",
    "                if (1.-frac_overlap) < threshold_for_change: \n",
    "                    # then district has not changed\n",
    "                    district_df.loc[ind,'border_change'] = 'same'\n",
    "                else:\n",
    "                    # district has changed\n",
    "                    district_df.loc[ind,'border_change'] = 'changed'\n",
    "                    print(ind)\n",
    "                    print(frac_overlap)\n",
    "                    \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute overlap percent between this district and last year's districts\n",
    "def district_overlap(this_year, district_df):\n",
    "    # loop over states so you only have to compare districts in-state\n",
    "    # otherwise, comparing each district to 434 other districts would be super slow\n",
    "    for ST in state_abbrs: \n",
    "        prev_year = this_year-2\n",
    "        # get the relevant districts\n",
    "        districts = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==this_year)]\n",
    "        districts_prev = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==prev_year)]\n",
    "\n",
    "        for ind,district in districts.iterrows(): # loop over districts in your current year\n",
    "            overlap_dict = {}\n",
    "            for ind_prev,district_prev in districts_prev.iterrows(): # loop over districts in previous year\n",
    "                shape_prev = district_prev['shape']\n",
    "                shape = district['shape']\n",
    "\n",
    "                # check if shapes intersect with themselves\n",
    "                if not (shape.is_valid and shape_prev.is_valid): \n",
    "                    # if they do, use buffer to correct this\n",
    "                    print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                    if not shape.is_valid:\n",
    "                        print(ind)\n",
    "                        shape = shape.buffer(0)\n",
    "                    if not shape_prev.is_valid:\n",
    "                        print(ind_prev)\n",
    "                        shape_prev = shape_prev.buffer(0)\n",
    "\n",
    "                # calculate frac overlap\n",
    "                area = shape.area # area of this district\n",
    "                area_prev = shape_prev.area\n",
    "                overlap_area = shape.intersection(shape_prev).area # area of overlap between shape and shape_prev\n",
    "                frac_overlap = overlap_area/area # fractional overlap between new and old district\n",
    "\n",
    "                if frac_overlap > 0.:\n",
    "                    overlap_dict[ind_prev] = frac_overlap\n",
    "\n",
    "            print(ind)\n",
    "            print(overlap_dict)\n",
    "            district_df.at[ind, 'overlap_frac'] = overlap_dict\n",
    "            \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_df = read_shapefiles([2010,2012,2014], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_year = 2014\n",
    "district_df = check_if_districts_changed(this_year, district_df, threshold_for_change=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_year = 2012\n",
    "district_df['overlap_frac'] = [np.nan]*district_df.shape[0] # make a blank column\n",
    "district_df['overlap_frac'] = district_df['overlap_frac'].astype(object) # convert to object \n",
    "\n",
    "overlap_df = district_overlap(this_year, district_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing a plot\n",
    "shape_feature = ShapelyFeature(record.geometry,\n",
    "                                ccrs.PlateCarree(), edgecolor='black')\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.set_xlim((-125, -67))\n",
    "ax.set_ylim((24,50))\n",
    "ax.add_feature(shape_feature, facecolor='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APCOMP 209",
   "language": "python",
   "name": "cs209"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
