{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from shapely.prepared import prep\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful arrays to translate between naming conventions\n",
    "\n",
    "election_year_list = np.array([1992, 1994, 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, \n",
    "                                   2014, 2016, 2018])\n",
    "congress_ID_list = np.array([103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116])\n",
    "\n",
    "state_names = np.array(['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', \n",
    "               'COLORADO', 'CONNECTICUT', 'DELAWARE', 'FLORIDA', 'GEORGIA', \n",
    "               'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', \n",
    "               'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', \n",
    "               'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', \n",
    "               'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', \n",
    "               'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', \n",
    "               'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', \n",
    "               'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', \n",
    "               'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'])\n",
    "\n",
    "state_abbrs = np.array(['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL',\n",
    "              'IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT',\n",
    "              'NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI',\n",
    "              'SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY'])\n",
    "\n",
    "state_fips = np.array([1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, \n",
    "                       24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
    "                       41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proj.4 string:\n",
    "# +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "congress_ID = '114'\n",
    "shpfilename = 'districtShapes-{0}/districts{0}.shp'.format(congress_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shapefiles(election_years,verbose=True):\n",
    "    # read in the standard dictionary \n",
    "    district_df = pickle.load(open('../Datasets/master_index.p','rb'))\n",
    "    district_df['shape'] = [np.nan]*district_df.shape[0] # make a blank column\n",
    "    district_df['shape'] = district_df['shape'].astype(object) # reassign to object so it can hold shapely stuff\n",
    "\n",
    "    for election_year in election_years:\n",
    "        # convert election year to \"Nth Congress\" \n",
    "        congress_ID = congress_ID_list[election_year_list==election_year][0]\n",
    "\n",
    "        # pre-2016 files come from http://cdmaps.polisci.ucla.edu/\n",
    "        # they are a bit cleaner\n",
    "        if election_year < 2016:\n",
    "            # read in the shapefile (must be named 'districtsN.shp' in a folder titled 'districtShapesN')\n",
    "            shpfilename = 'districtShapes-{0}/districts{0}.shp'.format(congress_ID)\n",
    "            reader = shpreader.Reader(shpfilename) \n",
    "            districts = reader.records() # get full records\n",
    "            geometries = reader.geometries() # get just the shape\n",
    "            \n",
    "            # put the shapefiles into the standard dictionary\n",
    "            for record in reader.records(): # loop over districts\n",
    "                attr = record.attributes # dictionary of information about the district\n",
    "                poly = record.geometry # coordinates of the district as a shapely polygon\n",
    "\n",
    "                # 1) get the state abbr of the district\n",
    "                if any(state_names==attr['STATENAME'].upper()): # filter out districts that aren't in states\n",
    "                    ST = state_abbrs[state_names==attr['STATENAME'].upper()][0]\n",
    "                else: # pretty much just Washington, DC\n",
    "                    print('{} is not a state.'.format(attr['STATENAME'].upper()))\n",
    "                    continue\n",
    "                # 2) get the id of the district\n",
    "                id_int = int(attr['DISTRICT'])\n",
    "                if id_int == 0: # change at-large district ID from 0 to 1 to play nice with our indexing convention.\n",
    "                    id_int = 1 # todo: do we want to change this back? Looks like 0 for at-large districts is the convention. \n",
    "                ID = '{0:02d}'.format(id_int)\n",
    "                # 3) put it all together into an index\n",
    "                ind = '{}_{}_{}'.format(ST, ID, election_year)\n",
    "                if verbose:\n",
    "                    print('{} was read in.'.format(ind))\n",
    "                # put the polygon in the dictionary\n",
    "                district_df.at[ind,'shape'] = poly\n",
    "            \n",
    "        # 2016 and later are US Census Bureau Tiger Line Files \n",
    "        # (and they're a bit messier)\n",
    "        if election_year >= 2016:\n",
    "            # read in the shapefile (must be named 'districtsN.shp' in a folder titled 'districtShapesN')\n",
    "            shpfilename = 'tl_2016_us_cd{0}/tl_{1}_us_cd{0}.shp'.format(congress_ID,election_year)\n",
    "            reader = shpreader.Reader(shpfilename) \n",
    "            districts = reader.records() # get full records\n",
    "            geometries = reader.geometries() # get just the shape\n",
    "\n",
    "            # put the shapefiles into the standard dictionary\n",
    "            for record in reader.records(): # loop over districts\n",
    "                attr = record.attributes # dictionary of information about the district\n",
    "                poly = record.geometry # coordinates of the district as a shapely polygon\n",
    "\n",
    "                # 1) get the state abbr of the district\n",
    "                if any(state_fips==int(attr['STATEFP'])): # filter out districts that aren't in states\n",
    "                    ST = state_abbrs[state_fips==int(attr['STATEFP'])][0]\n",
    "                else: # pretty much just Washington, DC\n",
    "                    print('{} is not a state.'.format(int(attr['STATEFP'])))\n",
    "                    continue\n",
    "                # 2) get the id of the district\n",
    "                if (attr['CD{}FP'.format(congress_ID)]=='ZZ'):\n",
    "                    print('District ID is ZZ, which indicates this is not a congressional district.')\n",
    "                    continue\n",
    "                else:\n",
    "                    id_int = int(attr['CD{}FP'.format(congress_ID)])\n",
    "                if id_int == 0: # change at-large district ID from 0 to 1 to play nice with our indexing convention.\n",
    "                    # todo: do we want to change this back? Looks like 0 for at-large districts is the convention. \n",
    "                    id_int = 1\n",
    "                ID = '{0:02d}'.format(id_int)\n",
    "                # 3) put it all together into an index\n",
    "                ind = '{}_{}_{}'.format(ST, ID, election_year)\n",
    "                if verbose:\n",
    "                    print('{} was read in.'.format(ind))\n",
    "                # put the polygon in the dictionary\n",
    "                district_df.at[ind,'shape'] = poly\n",
    "    \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find if a district has changed between last year and this year\n",
    "def check_if_districts_changed(this_year, district_df, threshold_for_change=0.1):\n",
    "    # loop over states so you only have to compare districts in-state\n",
    "    # otherwise, comparing each district to 434 other districts would be super slow\n",
    "    for ST in state_abbrs: \n",
    "        prev_year = this_year-2\n",
    "        # get the relevant districts\n",
    "        districts = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==this_year)]\n",
    "        districts_prev = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==prev_year)]\n",
    "        # loop over districts in your current year\n",
    "        for ind,district in districts.iterrows():\n",
    "            # find previous year's district\n",
    "            district_prev = districts_prev.loc[districts_prev['district']==district['district']]\n",
    "            ind_prev = district_prev.index\n",
    "\n",
    "            # determine whether district is new or borders have changed\n",
    "            if ind_prev.shape[0]==0: # if the district didn't exist last year\n",
    "                # then this district is new this year\n",
    "                district_df.loc['border_change',ind] = 'new'\n",
    "            else: \n",
    "                # check if the borders have changed\n",
    "                shape_prev = district_prev['shape'].values[0]\n",
    "                shape = district['shape']\n",
    "\n",
    "                # check if shapes intersect with themselves\n",
    "                if not (shape.is_valid and shape_prev.is_valid): \n",
    "                    # if they do, use buffer to correct this\n",
    "                    print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                    if not shape.is_valid:\n",
    "                        print(ind)\n",
    "                        shape = shape.buffer(0)\n",
    "                    if not shape_prev.is_valid:\n",
    "                        print(ind_prev)\n",
    "                        shape_prev = shape_prev.buffer(0)\n",
    "\n",
    "                # calculate overlap percent\n",
    "                area = shape.area # area of this district\n",
    "                area_prev = shape_prev.area\n",
    "                overlap_area = shape.intersection(shape_prev).area # area of overlap between shape and shape_prev\n",
    "                frac_overlap = overlap_area/np.max([area,area_prev]) # fractional overlap between new and old district\n",
    "                # divide by the larger of the old or new district\n",
    "                \n",
    "                if (1.-frac_overlap) < threshold_for_change: \n",
    "                    # then district has not changed\n",
    "                    district_df.loc[ind,'border_change'] = 'same'\n",
    "                else:\n",
    "                    # district has changed\n",
    "                    district_df.loc[ind,'border_change'] = 'changed'\n",
    "                    print(ind)\n",
    "                    print(frac_overlap)\n",
    "                    \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute overlap percent between this district and last year's districts\n",
    "def district_overlap(this_year, district_df):\n",
    "    # loop over states so you only have to compare districts in-state\n",
    "    # otherwise, comparing each district to 434 other districts would be super slow\n",
    "    for ST in state_abbrs: \n",
    "        prev_year = this_year-2\n",
    "        # get the relevant districts\n",
    "        districts = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==this_year)]\n",
    "        districts_prev = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==prev_year)]\n",
    "\n",
    "        for ind,district in districts.iterrows(): # loop over districts in your current year\n",
    "            overlap_dict = {}\n",
    "            for ind_prev,district_prev in districts_prev.iterrows(): # loop over districts in previous year\n",
    "                shape_prev = district_prev['shape']\n",
    "                shape = district['shape']\n",
    "\n",
    "                # check if shapes intersect with themselves\n",
    "                if not (shape.is_valid and shape_prev.is_valid): \n",
    "                    # if they do, use buffer to correct this\n",
    "                    print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                    if not shape.is_valid:\n",
    "                        print(ind)\n",
    "                        shape = shape.buffer(0)\n",
    "                    if not shape_prev.is_valid:\n",
    "                        print(ind_prev)\n",
    "                        shape_prev = shape_prev.buffer(0)\n",
    "\n",
    "                # calculate frac overlap\n",
    "                area = shape.area # area of this district\n",
    "                area_prev = shape_prev.area\n",
    "                overlap_area = shape.intersection(shape_prev).area # area of overlap between shape and shape_prev\n",
    "                frac_overlap = overlap_area/area # fractional overlap between new and old district\n",
    "\n",
    "                if frac_overlap > 0.:\n",
    "                    overlap_dict[ind_prev] = frac_overlap\n",
    "\n",
    "            print(ind)\n",
    "            print(overlap_dict)\n",
    "            district_df.at[ind, 'overlap_frac'] = overlap_dict\n",
    "            \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out if each district changed\n",
    "years = [2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018]\n",
    "\n",
    "# read in the data (make a fresh df)\n",
    "change_df = read_shapefiles(years, verbose=False)\n",
    "for year in years:\n",
    "    change_df = check_if_districts_changed(this_year, change_df)\n",
    "pickle(change_df, open('change.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the area overlap between this year's and last year's districts\n",
    "years = [2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018]\n",
    "\n",
    "# read in the data (make a fresh df)\n",
    "overlap_df = read_shapefiles(years, verbose=False)\n",
    "for year in years:\n",
    "    overlap_df = district_overlap(this_year, overlap_df, threshold_for_change=0.1)\n",
    "pickle(overlap_df, open('overlap_frac.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if both of these miraculously run without errors, pickle them in a combined df\n",
    "all_overlap_data_df = change_df.copy()\n",
    "all_overlap_data_df['overlap_frac'] = overlap_df['overlap_frac']\n",
    "pickle(all_overlap_data_df, open('all_overlap_data.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APCOMP 209",
   "language": "python",
   "name": "cs209"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
