{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cartopy.io.shapereader as shpreader\n",
    "from cartopy.feature import ShapelyFeature\n",
    "from shapely.prepared import prep\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful arrays to translate between naming conventions\n",
    "\n",
    "election_year_list = np.array([1992, 1994, 1996, 1998, 2000, 2002, 2004, 2006, 2008, 2010, 2012, \n",
    "                                   2014, 2016, 2018])\n",
    "congress_ID_list = np.array([103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116])\n",
    "\n",
    "state_names = np.array(['ALABAMA', 'ALASKA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', \n",
    "               'COLORADO', 'CONNECTICUT', 'DELAWARE', 'FLORIDA', 'GEORGIA', \n",
    "               'HAWAII', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', \n",
    "               'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', \n",
    "               'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', \n",
    "               'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', \n",
    "               'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', \n",
    "               'OREGON', 'PENNSYLVANIA', 'RHODE ISLAND', 'SOUTH CAROLINA', \n",
    "               'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', \n",
    "               'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING'])\n",
    "\n",
    "state_abbrs = np.array(['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL',\n",
    "              'IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT',\n",
    "              'NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI',\n",
    "              'SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY'])\n",
    "\n",
    "state_fips = np.array([1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, \n",
    "                       24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, \n",
    "                       41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proj.4 string:\n",
    "# +proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shapefiles(election_years,verbose=True):\n",
    "    \"\"\"\n",
    "    Reads in shapefiles from UCLA database (pre-2016) US Census TigerLine files (2016 on).\n",
    "    data sources: http://cdmaps.polisci.ucla.edu/\n",
    "                  https://www.census.gov/geo/maps-data/data/cbf/cbf_cds.html\n",
    "    Note that file names must be in the same folder as the code with the following format:\n",
    "        -pre-2016: districtShapes-NNN/districtsNNN.shp\n",
    "        -2016 on: must be named t1_YYYY_us_cdNNN/tl_YYYY_us_cdNNN.shp\n",
    "    ...where NNN is congress ID and YYYY is election year\n",
    "    \n",
    "    input:\n",
    "        election_years -- (list) Elections years of the shape files you want to read. Even years only. \n",
    "        verbose -- (bool) set to True if you want it to print every file as it reads it in\n",
    "    output:\n",
    "        district_df -- pandas data frame with index in format ST_00_YYYY (e.g. AL_01_2018) with \n",
    "                       shapefiles stored in a column named 'shape'.\n",
    "    \"\"\"\n",
    "    # read in the standard dictionary \n",
    "    district_df = pickle.load(open('../Datasets/master_index.p','rb'))\n",
    "    district_df['shape'] = [np.nan]*district_df.shape[0] # make a blank column\n",
    "    district_df['shape'] = district_df['shape'].astype(object) # reassign to object so it can hold shapely stuff\n",
    "\n",
    "    for election_year in election_years:\n",
    "        # convert election year to \"Nth Congress\" \n",
    "        congress_ID = congress_ID_list[election_year_list==election_year][0]\n",
    "\n",
    "        # pre-2016 files come from http://cdmaps.polisci.ucla.edu/\n",
    "        # they are a bit cleaner\n",
    "        if election_year < 2016:\n",
    "            # read in the shapefile (must be named 'districtsN.shp' in a folder titled 'districtShapesN')\n",
    "            shpfilename = 'districtShapes-{0}/districts{0}.shp'.format(congress_ID)\n",
    "            reader = shpreader.Reader(shpfilename) \n",
    "            districts = reader.records() # get full records\n",
    "            geometries = reader.geometries() # get just the shape\n",
    "            \n",
    "            # put the shapefiles into the standard dictionary\n",
    "            for record in reader.records(): # loop over districts\n",
    "                attr = record.attributes # dictionary of information about the district\n",
    "                poly = record.geometry # coordinates of the district as a shapely polygon\n",
    "\n",
    "                # 1) get the state abbr of the district\n",
    "                if any(state_names==attr['STATENAME'].upper()): # filter out districts that aren't in states\n",
    "                    ST = state_abbrs[state_names==attr['STATENAME'].upper()][0]\n",
    "                else: # pretty much just Washington, DC\n",
    "                    print('{} is not a state.'.format(attr['STATENAME'].upper()))\n",
    "                    continue\n",
    "                # 2) get the id of the district\n",
    "                id_int = int(attr['DISTRICT'])\n",
    "                if id_int == 0: # change at-large district ID from 0 to 1 to play nice with our indexing convention.\n",
    "                    id_int = 1 # todo: do we want to change this back? Looks like 0 for at-large districts is the convention. \n",
    "                ID = '{0:02d}'.format(id_int)\n",
    "                # 3) put it all together into an index\n",
    "                ind = '{}_{}_{}'.format(ST, ID, election_year)\n",
    "                if verbose:\n",
    "                    print('{} was read in.'.format(ind))\n",
    "                # put the polygon in the dictionary\n",
    "                district_df.at[ind,'shape'] = poly\n",
    "            \n",
    "        # 2016 and later are US Census Bureau Tiger Line Files \n",
    "        # (and they're a bit messier)\n",
    "        if election_year >= 2016:\n",
    "            # read in the shapefile (must be named 'tl_YYYY_us_cdN.shp' in a folder titled 't1_YYYY_us_cdN')\n",
    "            shpfilename = 'tl_{1}_us_cd{0}/tl_{1}_us_cd{0}.shp'.format(congress_ID,election_year)\n",
    "            reader = shpreader.Reader(shpfilename) \n",
    "            districts = reader.records() # get full records\n",
    "            geometries = reader.geometries() # get just the shape\n",
    "\n",
    "            # put the shapefiles into the standard dictionary\n",
    "            for record in reader.records(): # loop over districts\n",
    "                attr = record.attributes # dictionary of information about the district\n",
    "                poly = record.geometry # coordinates of the district as a shapely polygon\n",
    "\n",
    "                # 1) get the state abbr of the district\n",
    "                if any(state_fips==int(attr['STATEFP'])): # filter out districts that aren't in states\n",
    "                    ST = state_abbrs[state_fips==int(attr['STATEFP'])][0]\n",
    "                else: # pretty much just Washington, DC\n",
    "                    print('{} is not a state.'.format(int(attr['STATEFP'])))\n",
    "                    continue\n",
    "                # 2) get the id of the district\n",
    "                if (attr['CD{}FP'.format(congress_ID)]=='ZZ'):\n",
    "                    print('District ID is ZZ, which indicates this is not a congressional district.')\n",
    "                    continue\n",
    "                else:\n",
    "                    id_int = int(attr['CD{}FP'.format(congress_ID)])\n",
    "                if id_int == 0: # change at-large district ID from 0 to 1 to play nice with our indexing convention.\n",
    "                    # todo: do we want to change this back? Looks like 0 for at-large districts is the convention. \n",
    "                    id_int = 1\n",
    "                ID = '{0:02d}'.format(id_int)\n",
    "                # 3) put it all together into an index\n",
    "                ind = '{}_{}_{}'.format(ST, ID, election_year)\n",
    "                if verbose:\n",
    "                    print('{} was read in.'.format(ind))\n",
    "                # put the polygon in the dictionary\n",
    "                district_df.at[ind,'shape'] = poly\n",
    "    \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find if a district has changed between last year and this year\n",
    "def check_if_districts_changed(this_year, district_df, threshold_for_change=0.1):\n",
    "    \"\"\"\n",
    "    Checks if each district changed more than the set threshold since the last election year.\n",
    "    Change is a fraction of the district which overlaps with the previous year of that district (ranges 0-1).\n",
    "    If the total area of the district increases, the overlap area is divided by the largest of the two years.\n",
    "        (this prevents counting a district as unchanged if its area has increased)\n",
    "    \n",
    "    input:\n",
    "        this_year -- (int) Elections years of the districts you want to check. Even years only. \n",
    "        district_df -- (pd dataframe) dataframe with default indices and shapefiles stored in \n",
    "                       a column named 'shape'\n",
    "    output:\n",
    "        district_df -- pandas data frame with index in format ST_00_YYYY (e.g. AL_01_2018) \n",
    "                       with change from last year stored in a column called 'border_change'.\n",
    "                       Statuses:\n",
    "                           'same' - this district has not changed at all since the previous year\n",
    "                           'new' - indicates a district with this ID was not in this state last year\n",
    "                           'changed' - indicates the borders have changed from last year, but that \n",
    "                                       this district was present in its state last year\n",
    "    \"\"\"\n",
    "    # loop over states so you only have to compare districts in-state\n",
    "    # otherwise, comparing each district to 434 other districts would be super slow\n",
    "    for ST in state_abbrs: \n",
    "        prev_year = this_year-2\n",
    "        # get the relevant districts\n",
    "        districts = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==this_year)]\n",
    "        districts_prev = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==prev_year)]\n",
    "        # loop over districts in your current year\n",
    "        for ind,district in districts.iterrows():\n",
    "            # find previous year's district\n",
    "            district_prev = districts_prev.loc[districts_prev['district']==district['district']]\n",
    "            ind_prev = district_prev.index\n",
    "\n",
    "            # determine whether district is new or borders have changed\n",
    "            if ind_prev.shape[0]==0: # if the district didn't exist last year\n",
    "                # then this district is new this year\n",
    "                district_df.loc[ind,'border_change'] = 'new'\n",
    "            else: \n",
    "                # check if the borders have changed\n",
    "                shape_prev = district_prev['shape'].values[0]\n",
    "                shape = district['shape']\n",
    "\n",
    "                # check if shapes intersect with themselves\n",
    "                if not (shape.is_valid and shape_prev.is_valid): \n",
    "                    # if they do, use buffer to correct this\n",
    "                    print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                    if not shape.is_valid:\n",
    "                        print(ind)\n",
    "                        shape = shape.buffer(0)\n",
    "                    if not shape_prev.is_valid:\n",
    "                        print(ind_prev)\n",
    "                        shape_prev = shape_prev.buffer(0)\n",
    "\n",
    "                # calculate overlap percent\n",
    "                area = shape.area # area of this district\n",
    "                area_prev = shape_prev.area\n",
    "                overlap_area = shape.intersection(shape_prev).area # area of overlap between shape and shape_prev\n",
    "                frac_overlap = overlap_area/np.max([area,area_prev]) # fractional overlap between new and old district\n",
    "                # divide by the larger of the old or new district\n",
    "                \n",
    "                if (1.-frac_overlap) < threshold_for_change: \n",
    "                    # then district has not changed\n",
    "                    district_df.loc[ind,'border_change'] = 'same'\n",
    "                else:\n",
    "                    # district has changed\n",
    "                    district_df.loc[ind,'border_change'] = 'changed'\n",
    "                    print(ind)\n",
    "                    print(frac_overlap)\n",
    "                    \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute overlap percent between this district and last year's districts\n",
    "def district_overlap(this_year, district_df):\n",
    "    \"\"\"\n",
    "    Finds the fractional overlap between this year's district and the previous year's districts. \n",
    "    i.e., if a Florida's 1st district has changed its borders from 2014 to 2016, it may be made up of:\n",
    "        20% of its area may come from district 2 in 2014\n",
    "        40% of its area may come from district 3 in 2014\n",
    "        10% of its area may come from district 4 in 2014\n",
    "    \n",
    "    input:\n",
    "        this_year -- (int) Elections years of the districts you want to check. Even years only. \n",
    "        district_df -- (pd dataframe) dataframe with default indices and shapefiles stored in \n",
    "                       a column named 'shape'\n",
    "    output:\n",
    "        district_df -- pandas data frame with index in format ST_00_YYYY (e.g. AL_01_2018) \n",
    "                       with fractional overlap stored in a column called 'fractional_overlap'.\n",
    "                       \n",
    "                       Each district has a dictionary where the keys are the indicies of the previous\n",
    "                       districts which overlap with our district, and the values are the fractional overlap.\n",
    "    \"\"\"\n",
    "    # loop over states so you only have to compare districts in-state\n",
    "    # otherwise, comparing each district to 434 other districts would be super slow\n",
    "    for ST in state_abbrs: \n",
    "        prev_year = this_year-2\n",
    "        # get the relevant districts\n",
    "        districts = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==this_year)]\n",
    "        districts_prev = district_df.loc[np.logical_and(district_df['state']==ST,\n",
    "                                                 district_df['year']==prev_year)]\n",
    "\n",
    "        for ind,district in districts.iterrows(): # loop over districts in your current year\n",
    "            overlap_dict = {}\n",
    "            shape = district['shape']\n",
    "            area = shape.area # area of this district\n",
    "            # check if shapes intersect with themselves\n",
    "            if not (shape.is_valid and shape_prev.is_valid): \n",
    "                # if they do, use buffer to correct this\n",
    "                print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                if not shape.is_valid:\n",
    "                    print(ind)\n",
    "                    shape = shape.buffer(0)\n",
    "                if not shape_prev.is_valid:\n",
    "                    print(ind_prev)\n",
    "                    shape_prev = shape_prev.buffer(0)\n",
    "            for ind_prev,district_prev in districts_prev.iterrows(): # loop over districts in previous year\n",
    "                shape_prev = district_prev['shape']\n",
    "\n",
    "                # check if shapes intersect with themselves\n",
    "                if not (shape.is_valid and shape_prev.is_valid): \n",
    "                    # if they do, use buffer to correct this\n",
    "                    print('The following polygons intersected with themselves. Attempting to buffer shape...')\n",
    "                    if not shape.is_valid:\n",
    "                        print(ind)\n",
    "                        shape = shape.buffer(0)\n",
    "                    if not shape_prev.is_valid:\n",
    "                        print(ind_prev)\n",
    "                        shape_prev = shape_prev.buffer(0)\n",
    "\n",
    "                # calculate frac overlap\n",
    "                area_prev = shape_prev.area\n",
    "                overlap_area = shape.intersection(shape_prev).area # area of overlap between shape and shape_prev\n",
    "                frac_overlap = overlap_area/area # fractional overlap between new and old district\n",
    "\n",
    "                if frac_overlap > 0.:\n",
    "                    overlap_dict[ind_prev] = frac_overlap\n",
    "\n",
    "            print(ind)\n",
    "            print(overlap_dict)\n",
    "            district_df.at[ind, 'overlap_frac'] = overlap_dict\n",
    "            \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(district_df):\n",
    "    \"\"\"\n",
    "    Finds the centroid of a district in lon,lat. \n",
    "    \n",
    "    input: \n",
    "        district_df -- (pd dataframe) dataframe with default indices and shapefiles stored in \n",
    "                       a column named 'shape'\n",
    "    output:\n",
    "        district_df -- pandas data frame with index in format ST_00_YYYY (e.g. AL_01_2018) \n",
    "                       with centroid stored in a column called 'centroid'.\n",
    "                       The centroid is calculated as a lon,lat on a Cartesian plane.\n",
    "                       It ignores spherical geometry. \n",
    "                       The centroid is stored as a tuple in the form (lon,lat)\n",
    "    \"\"\"\n",
    "    # add column\n",
    "    district_df['centroid'] = [np.nan]*district_df.shape[0] # make a blank column\n",
    "    district_df['centroid'] = district_df['centroid'].astype(object) # reassign to object so it can hold shapely stuff\n",
    "    \n",
    "    for ind, district in district_df.iterrows():\n",
    "        shape = district['shape']\n",
    "        if pd.isnull(district['shape']): # if there's no shape, fill it with a nan\n",
    "            district_df.at[ind, 'centroid'] = np.nan\n",
    "        else:\n",
    "            centroid = shape.centroid.coords\n",
    "            district_df.at[ind, 'centroid'] = centroid # in units of lat/lon\n",
    "            \n",
    "    return district_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(district_df):\n",
    "    # add column\n",
    "    #todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTRICT OF COLUMBIA is not a state.\n",
      "DISTRICT OF COLUMBIA is not a state.\n",
      "DISTRICT OF COLUMBIA is not a state.\n",
      "DISTRICT OF COLUMBIA is not a state.\n",
      "DISTRICT OF COLUMBIA is not a state.\n",
      "DISTRICT OF COLUMBIA is not a state.\n",
      "DISTRICT OF COLUMBIA is not a state.\n",
      "11 is not a state.\n",
      "60 is not a state.\n",
      "66 is not a state.\n",
      "69 is not a state.\n",
      "72 is not a state.\n",
      "78 is not a state.\n",
      "District ID is ZZ, which indicates this is not a congressional district.\n",
      "District ID is ZZ, which indicates this is not a congressional district.\n",
      "District ID is ZZ, which indicates this is not a congressional district.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda2/envs/cs209/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2581\u001b[0m             \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CA_47_2018'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-fdb318100079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0myears\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2006\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2008\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2010\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2016\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2018\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcentroid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_shapefiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0mcentroid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroid_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-82564ddfeaad>\u001b[0m in \u001b[0;36mread_shapefiles\u001b[0;34m(election_years, verbose)\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} was read in.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;31m# put the polygon in the dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mdistrict_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'shape'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistrict_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs209/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs209/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   2585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m             \u001b[0;31m# set using a non-recursive method & reset the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs209/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/cs209/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                         raise ValueError('Must have equal len keys and value '\n\u001b[0m\u001b[1;32m    607\u001b[0m                                          'when setting with an iterable')\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "# get centroid coords for everything \n",
    "years = [2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018]\n",
    "\n",
    "centroid_df = read_shapefiles(years, verbose=False)\n",
    "for year in years:\n",
    "     centroid_df = get_centroid(centroid_df)\n",
    "pickle.dump(centroid_df, open('centroid.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out if each district changed\n",
    "years = [2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018]\n",
    "\n",
    "# read in the data (make a fresh df)\n",
    "change_df = read_shapefiles(years, verbose=False)\n",
    "for year in years:\n",
    "    change_df = check_if_districts_changed(this_year, change_df)\n",
    "pickle.dump(change_df, open('change.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out the area overlap between this year's and last year's districts\n",
    "years = [2002, 2004, 2006, 2008, 2010, 2012, 2014, 2016, 2018]\n",
    "\n",
    "# read in the data (make a fresh df)\n",
    "overlap_df = read_shapefiles(years, verbose=False)\n",
    "for year in years:\n",
    "    overlap_df = district_overlap(this_year, overlap_df, threshold_for_change=0.1)\n",
    "pickle.dump(overlap_df, open('overlap_frac.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all of these miraculously run without errors, pickle them in a combined df\n",
    "all_overlap_data_df = change_df.copy()\n",
    "all_overlap_data_df['overlap_frac'] = overlap_df['overlap_frac']\n",
    "all_overlap_data_df['centroid'] = overlap_df['centroid']\n",
    "pickle.dump(all_overlap_data_df, open('all_overlap_data.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "APCOMP 209",
   "language": "python",
   "name": "cs209"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
